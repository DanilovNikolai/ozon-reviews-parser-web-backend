// app.js
const express = require('express');
const { parseReviewsFromUrl } = require('./main');
const { downloadFromS3, uploadScreenshot } = require('./services/s3');
const { readExcelLinks, writeExcelReviews } = require('./services/excel');
const fs = require('fs');
const { getLogBuffer, logWithCapture, warnWithCapture, errorWithCapture } = require('./utils');

const app = express();
app.use(express.json({ limit: '10mb' }));

// ===== Ğ¥Ğ ĞĞĞ˜Ğ›Ğ˜Ğ©Ğ• Ğ—ĞĞ”ĞĞ§ =====
const jobs = {}; // jobId -> { ... }

function createJobId() {
  return Date.now().toString(36) + '_' + Math.random().toString(36).slice(2, 8);
}

/**
 * Ğ¤Ğ¾Ğ½Ğ¾Ğ²Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
 */
async function runJob(jobId, { s3InputFileUrl, mode }) {
  const job = jobs[jobId];
  if (!job) return;

  let allResults = [];
  let s3OutputUrl = null;
  let errorMessage = null;

  try {
    job.status = 'downloading';
    job.updatedAt = Date.now();

    // 1) Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Excel
    const localInputPath = await downloadFromS3(s3InputFileUrl);

    // 2) ĞŸÑ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ ÑÑÑ‹Ğ»ĞºĞ¸
    const urls = await readExcelLinks(localInputPath);
    job.totalUrls = urls.length;
    job.processedUrls = 0;
    job.status = 'parsing';
    job.updatedAt = Date.now();

    logWithCapture(`ğŸ”— [ĞŸÑ€Ğ¾Ñ†ĞµÑÑ ${jobId}] ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ ÑÑÑ‹Ğ»Ğ¾Ğº: ${urls.length}`);

    // 3) ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ ÑÑÑ‹Ğ»ĞºĞ¸
    for (const url of urls) {
      if (job.cancelRequested) {
        job.status = 'cancelled';
        job.updatedAt = Date.now();
        return;
      }

      job.currentUrl = url;
      job.currentPage = 0;
      job.collectedReviews = 0;
      job.updatedAt = Date.now();

      logWithCapture(`â–¶ [ĞŸÑ€Ğ¾Ñ†ĞµÑÑ ${jobId}] ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°: ${url}`);

      try {
        const result = await parseReviewsFromUrl(
          url,
          mode,
          // Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ â†’ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ collectedReviews
          (partial) => {
            job.collectedReviews += partial.reviews.length;
            job.updatedAt = Date.now();

            logWithCapture(
              `[ĞŸÑ€Ğ¾Ñ†ĞµÑÑ ${jobId}] ĞŸÑ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ: ${partial.reviews.length} Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²`
            );
          },
          // ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‘Ğ¼ job Ğ²Ğ½ÑƒÑ‚Ñ€ÑŒ main.js, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑÑ‚ÑŒ currentPage/totalReviewsCount
          job
        );

        allResults.push({
          ...result,
          error: null,
          errorOccurred: false,
        });
      } catch (err) {
        if (err.message === 'ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ¾Ñ‚Ğ¼ĞµĞ½Ñ‘Ğ½ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼') {
          job.status = 'cancelled';
          job.error = null;
          job.updatedAt = Date.now();
          logWithCapture(`â›” [ĞŸÑ€Ğ¾Ñ†ĞµÑÑ ${jobId}] ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼`);
          return;
        }

        errorWithCapture(`âŒ [ĞŸÑ€Ğ¾Ñ†ĞµÑÑ ${jobId}] ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° ${url}: ${err.message}`);

        allResults.push({
          url,
          productName: url.match(/product\/([^/]+)/)?.[1] || 'Ğ¢Ğ¾Ğ²Ğ°Ñ€',
          reviews: [],
          error: err.message,
          errorOccurred: true,
          logs: getLogBuffer(),
        });

        errorMessage = `ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° ${url}: ${err.message}`;
        break;
      } finally {
        job.processedUrls += 1;
        job.updatedAt = Date.now();
      }
    }
  } catch (err) {
    errorWithCapture(`âŒ [ĞŸÑ€Ğ¾Ñ†ĞµÑÑ ${jobId}] Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: ${err}`);
    if (!errorMessage) errorMessage = err.message;
  }

  // 4) Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Excel
  try {
    s3OutputUrl = await writeExcelReviews(allResults);
  } catch (err) {
    errorWithCapture(`âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Excel: ${err.message}`);
    if (!errorMessage) errorMessage = err.message;
  }

  // 5) Ğ¡ĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚Ñ‹
  const screenshots = ['/tmp/debug_hash.png', '/tmp/debug_reviews.png'];

  for (const file of screenshots) {
    try {
      if (fs.existsSync(file)) {
        await uploadScreenshot(file);
        logWithCapture(`[ĞŸÑ€Ğ¾Ñ†ĞµÑÑ ${jobId}] ğŸ“¤ Ğ¡ĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½: ${file}`);
      }
    } catch (err) {
      warnWithCapture(`[ĞŸÑ€Ğ¾Ñ†ĞµÑÑ ${jobId}] âš  ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ ÑĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚Ğ°: ${err.message}`);
    }
  }

  // 6) Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾
  job.s3OutputUrl = s3OutputUrl || null;
  job.error = errorMessage || null;
  job.status = errorMessage ? 'error' : 'completed';
  job.updatedAt = Date.now();

  logWithCapture(`âœ” [ĞŸÑ€Ğ¾Ñ†ĞµÑÑ ${jobId}] Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾: ${job.status}`);
}

// ====== API ======

app.post('/parse', async (req, res) => {
  const { s3InputFileUrl, mode } = req.body;
  if (!s3InputFileUrl) {
    return res.status(400).json({ success: false, error: 'ĞĞµ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ½ s3InputFileUrl' });
  }

  const jobId = createJobId();
  const now = Date.now();

  jobs[jobId] = {
    id: jobId,
    status: 'queued',
    error: null,
    s3InputFileUrl,
    s3OutputUrl: null,
    mode: mode || '3',
    createdAt: now,
    updatedAt: now,

    totalUrls: 0,
    processedUrls: 0,

    currentUrl: null,
    currentPage: 0,
    collectedReviews: 0,
    totalReviewsCount: 0,

    cancelRequested: false,
  };

  logWithCapture(`ğŸ§© Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° ${jobId}`);

  (async () => {
    await runJob(jobId, { s3InputFileUrl, mode });
  })();

  return res.json({ success: true, jobId });
});

app.get('/parse/:jobId/status', (req, res) => {
  const job = jobs[req.params.jobId];

  if (!job) return res.status(404).json({ success: false, error: 'Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°' });

  return res.json({
    success: true,
    ...job,
  });
});

app.post('/parse/:jobId/cancel', (req, res) => {
  const job = jobs[req.params.jobId];

  if (!job) {
    return res.status(404).json({ success: false, error: 'Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°' });
  }

  job.cancelRequested = true;
  job.updatedAt = Date.now();

  return res.json({ success: true, message: 'ĞÑ‚Ğ¼ĞµĞ½Ğ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑˆĞµĞ½Ğ°' });
});

app.listen(process.env.PORT || 8080, () => {
  logWithCapture(`ğŸŸ¢ Parser started`);
});
